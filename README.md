# üõ°Ô∏è Cybersecurity Threat Detection System using Amazon SageMaker

An end-to-end **machine learning pipeline** that detects cybersecurity threats from network traffic data using **Amazon SageMaker**.  
This project covers the entire lifecycle ‚Äî from **data preprocessing** to **automated retraining** with **SageMaker Pipelines** and **EventBridge**.

---

## üöÄ Highlights
- Achieved **95%+ accuracy** using **XGBoost** on the UNSW-NB15 dataset  
- Fully automated **ML workflow** using SageMaker Pipelines  
- Real-time **threat detection endpoint** deployed on SageMaker  
- **EventBridge automation** for scheduled retraining  
- Clean, modular repo with Jupyter notebooks and result screenshots  

---
---

## üß± Architecture Diagram

The following diagram illustrates the end-to-end **Cybersecurity Threat Detection Pipeline** built on AWS:

![Cybersecurity Threat Detection Pipeline](screenshots/architecture2.png)

**Workflow Summary:**
1. **Amazon S3** ‚Äì Collects raw network logs.  
2. **AWS Lambda** ‚Äì Processes and transforms logs into structured datasets.  
3. **Amazon S3** ‚Äì Stores the processed dataset.  
4. **Amazon SageMaker** ‚Äì Trains the XGBoost model using pipelines.  
5. **AWS IAM** ‚Äì Manages access and permissions.  
6. **Amazon CloudWatch** ‚Äì Logs metrics and monitors endpoint activity.  
7. **SageMaker Endpoint** ‚Äì Deployed model for real-time threat detection.  

---
---

## ‚öôÔ∏è Project Phases

This project was developed in **four main phases**, following a complete ML lifecycle using **Amazon SageMaker**.

---

### üßπ Phase 1 ‚Äî Data Preprocessing
**Notebook:** `notebooks/data_preprocessing.ipynb`

- Loaded the **UNSW-NB15 dataset** from S3.
- Cleaned missing data and removed unnecessary columns.
- Encoded categorical variables and normalized numerical features.
- Saved processed dataset back to S3 for training.

---

### üß† Phase 2 ‚Äî Model Training and Evaluation
**Notebook:** `notebooks/02modeltraining_and_evaluation.ipynb`

- Trained an **XGBoost binary classification model** using SageMaker.
- Optimized hyperparameters for best accuracy and F1-score.
- Evaluated model performance on a test dataset.

**Results:**
| Metric | Value |
|--------|--------|
| Accuracy | 95.6% |
| Precision | 0.96 |
| Recall | 0.98 |
| F1-Score | 0.97 |

**Model Output (S3):**
**Screenshots:**
| Screenshot | Description |
|-------------|-------------|
| ![xgboost_endpoint](screenshots/xgboost_endpoint.png) | SageMaker XGBoost training job successfully completed |
| ![xgboost_prediction_output](screenshots/xgboost_prediction_output.png) | Model evaluation and prediction output from notebook |

---

### üöÄ Phase 3 ‚Äî Model Deployment
**Notebook:** `notebooks/03model_deployment.ipynb`

- Registered the trained **XGBoost model** as a SageMaker Model.  
- Created a **SageMaker Endpoint** to enable real-time inference.  
- Tested the endpoint with sample input data to verify predictions.  
- Integrated CloudWatch to monitor endpoint performance.  

**Deployment Details:**
- **Model Name:** `cybersecurity-threat-xgboost`
- **Endpoint Name:** `cybersecurity-xgboost-endpoint`
- **IAM Role:** `arn:aws:iam::907759099913:role/SageMakerCybersecurityRole`

---

### üîÑ Phase 4 ‚Äî Automation with SageMaker Pipelines & EventBridge
**Notebook:** `notebooks/04automation_pipeline.ipynb`

- Built an **automated ML workflow** using **Amazon SageMaker Pipelines**.  
- Defined a pipeline that automatically trains and stores the model artifacts in S3.  
- Configured **AWS EventBridge** to trigger retraining automatically when new data is uploaded to the S3 bucket.  
- Ensured full pipeline execution from data input ‚Üí model retraining ‚Üí output storage.

**Pipeline Configuration:**
- **Pipeline Name:** `simple-cybersecurity-pipeline`
- **Training Step:** `TrainCybersecurityModel`
- **Instance Type:** `ml.m5.large`
- 
**Screenshots:**
| Screenshot | Description |
|-------------|-------------|
| ![pipeline_execution_success](screenshots/pipeline_execution_success.png) | SageMaker pipeline execution showing status **Completed** |
| ![pipeline_output_s3](screenshots/pipeline_output_s3.png) | S3 bucket containing generated pipeline output model artifacts |
| ![eventbridge_rule](screenshots/eventbridge_rule.png) | AWS EventBridge rule configured to trigger automatic model retraining |

---

‚úÖ **Summary:**
This phase successfully automated the **entire ML lifecycle** ‚Äî from data ingestion and model retraining to deployment triggers ‚Äî using **SageMaker Pipelines** and **EventBridge**.  
The system can now **auto-train and deploy** models whenever new network data is ingested.

---
