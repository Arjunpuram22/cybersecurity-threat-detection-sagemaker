{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "514b9d7c-01c3-433b-93d9-1a3a2a89f443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175341, 45)\n",
      "Index(['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
      "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
      "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
      "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
      "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
      "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
      "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
      "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label'],\n",
      "      dtype='object')\n",
      "   id       dur proto service state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
      "0   1  0.121478   tcp       -   FIN      6      4     258     172  74.087490   \n",
      "1   2  0.649902   tcp       -   FIN     14     38     734   42014  78.473372   \n",
      "2   3  1.623129   tcp       -   FIN      8     16     364   13186  14.170161   \n",
      "3   4  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108   \n",
      "4   5  0.449454   tcp       -   FIN     10      6     534     268  33.373826   \n",
      "\n",
      "   ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
      "0  ...                 1               1             0           0   \n",
      "1  ...                 1               2             0           0   \n",
      "2  ...                 1               3             0           0   \n",
      "3  ...                 1               3             1           1   \n",
      "4  ...                 1              40             0           0   \n",
      "\n",
      "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
      "0                 0           1           1                0      Normal   \n",
      "1                 0           1           6                0      Normal   \n",
      "2                 0           2           6                0      Normal   \n",
      "3                 0           2           1                0      Normal   \n",
      "4                 0           2          39                0      Normal   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "label\n",
      "1    119341\n",
      "0     56000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Setup S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Download the file into memory\n",
    "response = s3_client.get_object(Bucket='arjunp-cybersecurity-ml-data1', Key='raw-data/UNSW_NB15_training-set.csv')\n",
    "\n",
    "# Read it into pandas\n",
    "df = pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "\n",
    "# Explore\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.head())\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a1c8aa-3a02-42da-8402-275e909257d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175341, 198)\n",
      "        dur     spkts     dpkts    sbytes    dbytes      rate      sttl  \\\n",
      "0 -0.191029 -0.104456 -0.135769 -0.049134 -0.102726 -0.576371  0.703839   \n",
      "1 -0.109485 -0.046014  0.172599 -0.046410  0.188544 -0.576345 -1.141901   \n",
      "2  0.040699 -0.089845 -0.026933 -0.048527 -0.012133 -0.576734 -1.141901   \n",
      "3  0.049729 -0.060624 -0.063212 -0.047016 -0.098563 -0.576737 -1.141901   \n",
      "4 -0.140417 -0.075235 -0.117630 -0.047554 -0.102057 -0.576617  0.723268   \n",
      "\n",
      "       dttl     sload     dload  ...  service_ssl  state_CON  state_ECO  \\\n",
      "0  1.578100 -0.389897 -0.273700  ...    -0.017874  -0.284764  -0.008273   \n",
      "1  1.560002 -0.389928 -0.069233  ...    -0.017874  -0.284764  -0.008273   \n",
      "2  1.560002 -0.389964 -0.252044  ...    -0.017874  -0.284764  -0.008273   \n",
      "3  1.560002 -0.389958 -0.275821  ...    -0.017874  -0.284764  -0.008273   \n",
      "4  1.560002 -0.389927 -0.275561  ...    -0.017874  -0.284764  -0.008273   \n",
      "\n",
      "   state_FIN  state_INT  state_PAR  state_REQ  state_RST  state_URN  state_no  \n",
      "0   1.119382  -0.940239  -0.002388   -0.10717  -0.021762  -0.002388 -0.002388  \n",
      "1   1.119382  -0.940239  -0.002388   -0.10717  -0.021762  -0.002388 -0.002388  \n",
      "2   1.119382  -0.940239  -0.002388   -0.10717  -0.021762  -0.002388 -0.002388  \n",
      "3   1.119382  -0.940239  -0.002388   -0.10717  -0.021762  -0.002388 -0.002388  \n",
      "4   1.119382  -0.940239  -0.002388   -0.10717  -0.021762  -0.002388 -0.002388  \n",
      "\n",
      "[5 rows x 198 columns]\n",
      "                   mean       std\n",
      "dur       -3.241878e-18  1.000003\n",
      "spkts     -1.426426e-17  1.000003\n",
      "dpkts      5.187005e-18  1.000003\n",
      "sbytes    -1.053610e-18  1.000003\n",
      "dbytes     1.410217e-17  1.000003\n",
      "...                 ...       ...\n",
      "state_PAR -1.347406e-18  1.000003\n",
      "state_REQ  3.930777e-18  1.000003\n",
      "state_RST -2.917690e-18  1.000003\n",
      "state_URN  7.902078e-19  1.000003\n",
      "state_no   7.902078e-19  1.000003\n",
      "\n",
      "[198 rows x 2 columns]\n",
      "dur         -0.0\n",
      "spkts       -0.0\n",
      "dpkts        0.0\n",
      "sbytes      -0.0\n",
      "dbytes       0.0\n",
      "            ... \n",
      "state_PAR   -0.0\n",
      "state_REQ    0.0\n",
      "state_RST   -0.0\n",
      "state_URN    0.0\n",
      "state_no     0.0\n",
      "Length: 197, dtype: float64\n",
      "dur          1.0\n",
      "spkts        1.0\n",
      "dpkts        1.0\n",
      "sbytes       1.0\n",
      "dbytes       1.0\n",
      "            ... \n",
      "state_PAR    1.0\n",
      "state_REQ    1.0\n",
      "state_RST    1.0\n",
      "state_URN    1.0\n",
      "state_no     1.0\n",
      "Length: 197, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Drop irrelevant columns ---\n",
    "df = df.drop(columns=['id', 'attack_cat'])\n",
    "\n",
    "# --- 2. Feature engineering BEFORE encoding/scaling ---\n",
    "df['byte_ratio'] = df['sbytes'] / (df['dbytes'] + 1)\n",
    "df['is_common_port'] = df['ct_dst_sport_ltm'].isin([80, 443, 22]).astype(int)\n",
    "df['flow_intensity'] = (df['spkts'] + df['dpkts']) / (df['dur'] + 1e-6)\n",
    "\n",
    "# --- 3. One-hot encode categorical columns ---\n",
    "categorical_cols = ['proto', 'service', 'state']\n",
    "df = pd.get_dummies(df, columns=categorical_cols)\n",
    "\n",
    "# Convert booleans to ints\n",
    "df = df.astype({col: 'int' for col in df.columns if df[col].dtype == 'bool'})\n",
    "\n",
    "# --- 4. Scale numerical features (except label) ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_cols.remove('label')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# --- Checks ---\n",
    "print(df.shape)                                  # Final number of rows & columns\n",
    "print(df.head())                                 # Preview first few rows\n",
    "print(df.describe().T[['mean', 'std']])          # Confirm scaling stats\n",
    "print(df[numerical_cols].mean().round(3))        # Should be ~0\n",
    "print(df[numerical_cols].std().round(3))         # Should be ~1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ca5a51b-f06d-441a-a51b-2ce2dea19261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data uploaded to: s3://arjunp-cybersecurity-ml-data1/processed-data/preprocessed_data.csv\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Create SageMaker session and define bucket\n",
    "session = sagemaker.Session()\n",
    "bucket = 'arjunp-cybersecurity-ml-data1'  # Replace with your actual S3 bucket name\n",
    "processed_prefix = 'processed-data'      # Folder in S3 to store processed files\n",
    "\n",
    "# Save preprocessed data locally\n",
    "df.to_csv('preprocessed_data.csv', index=False)\n",
    "\n",
    "# Upload to S3 inside the 'processed-data/' folder\n",
    "s3_path = session.upload_data(\n",
    "    path='preprocessed_data.csv',\n",
    "    bucket=bucket,\n",
    "    key_prefix=processed_prefix\n",
    ")\n",
    "\n",
    "print(f\"Preprocessed data uploaded to: {s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a56d8ceb-27aa-4dd3-b71c-6b6ef2bd6cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample file 'sample_unsw.csv' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Setup S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Define your bucket and object key\n",
    "bucket_name = 'arjunp-cybersecurity-ml-data1'\n",
    "object_key = 'raw-data/UNSW_NB15_training-set.csv'\n",
    "\n",
    "# Download the file from S3 directly into memory\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "\n",
    "# Read it into pandas\n",
    "df = pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "\n",
    "# Create sample (100 rows)\n",
    "sample_df = df.head(100)\n",
    "\n",
    "# Save to a local CSV file\n",
    "sample_df.to_csv('sample_unsw.csv', index=False)\n",
    "\n",
    "print(\"✅ Sample file 'sample_unsw.csv' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a43cca0-bbfc-423e-ae59-43c2a54d6382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>...</th>\n",
       "      <th>service_ssl</th>\n",
       "      <th>state_CON</th>\n",
       "      <th>state_ECO</th>\n",
       "      <th>state_FIN</th>\n",
       "      <th>state_INT</th>\n",
       "      <th>state_PAR</th>\n",
       "      <th>state_REQ</th>\n",
       "      <th>state_RST</th>\n",
       "      <th>state_URN</th>\n",
       "      <th>state_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.191029</td>\n",
       "      <td>-0.104456</td>\n",
       "      <td>-0.135769</td>\n",
       "      <td>-0.049134</td>\n",
       "      <td>-0.102726</td>\n",
       "      <td>-0.576371</td>\n",
       "      <td>0.703839</td>\n",
       "      <td>1.578100</td>\n",
       "      <td>-0.389897</td>\n",
       "      <td>-0.273700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017874</td>\n",
       "      <td>-0.284764</td>\n",
       "      <td>-0.008273</td>\n",
       "      <td>1.119382</td>\n",
       "      <td>-0.940239</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.10717</td>\n",
       "      <td>-0.021762</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.002388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.109485</td>\n",
       "      <td>-0.046014</td>\n",
       "      <td>0.172599</td>\n",
       "      <td>-0.046410</td>\n",
       "      <td>0.188544</td>\n",
       "      <td>-0.576345</td>\n",
       "      <td>-1.141901</td>\n",
       "      <td>1.560002</td>\n",
       "      <td>-0.389928</td>\n",
       "      <td>-0.069233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017874</td>\n",
       "      <td>-0.284764</td>\n",
       "      <td>-0.008273</td>\n",
       "      <td>1.119382</td>\n",
       "      <td>-0.940239</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.10717</td>\n",
       "      <td>-0.021762</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.002388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040699</td>\n",
       "      <td>-0.089845</td>\n",
       "      <td>-0.026933</td>\n",
       "      <td>-0.048527</td>\n",
       "      <td>-0.012133</td>\n",
       "      <td>-0.576734</td>\n",
       "      <td>-1.141901</td>\n",
       "      <td>1.560002</td>\n",
       "      <td>-0.389964</td>\n",
       "      <td>-0.252044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017874</td>\n",
       "      <td>-0.284764</td>\n",
       "      <td>-0.008273</td>\n",
       "      <td>1.119382</td>\n",
       "      <td>-0.940239</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.10717</td>\n",
       "      <td>-0.021762</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.002388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049729</td>\n",
       "      <td>-0.060624</td>\n",
       "      <td>-0.063212</td>\n",
       "      <td>-0.047016</td>\n",
       "      <td>-0.098563</td>\n",
       "      <td>-0.576737</td>\n",
       "      <td>-1.141901</td>\n",
       "      <td>1.560002</td>\n",
       "      <td>-0.389958</td>\n",
       "      <td>-0.275821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017874</td>\n",
       "      <td>-0.284764</td>\n",
       "      <td>-0.008273</td>\n",
       "      <td>1.119382</td>\n",
       "      <td>-0.940239</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.10717</td>\n",
       "      <td>-0.021762</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.002388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.140417</td>\n",
       "      <td>-0.075235</td>\n",
       "      <td>-0.117630</td>\n",
       "      <td>-0.047554</td>\n",
       "      <td>-0.102057</td>\n",
       "      <td>-0.576617</td>\n",
       "      <td>0.723268</td>\n",
       "      <td>1.560002</td>\n",
       "      <td>-0.389927</td>\n",
       "      <td>-0.275561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017874</td>\n",
       "      <td>-0.284764</td>\n",
       "      <td>-0.008273</td>\n",
       "      <td>1.119382</td>\n",
       "      <td>-0.940239</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.10717</td>\n",
       "      <td>-0.021762</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.002388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur     spkts     dpkts    sbytes    dbytes      rate      sttl  \\\n",
       "0 -0.191029 -0.104456 -0.135769 -0.049134 -0.102726 -0.576371  0.703839   \n",
       "1 -0.109485 -0.046014  0.172599 -0.046410  0.188544 -0.576345 -1.141901   \n",
       "2  0.040699 -0.089845 -0.026933 -0.048527 -0.012133 -0.576734 -1.141901   \n",
       "3  0.049729 -0.060624 -0.063212 -0.047016 -0.098563 -0.576737 -1.141901   \n",
       "4 -0.140417 -0.075235 -0.117630 -0.047554 -0.102057 -0.576617  0.723268   \n",
       "\n",
       "       dttl     sload     dload  ...  service_ssl  state_CON  state_ECO  \\\n",
       "0  1.578100 -0.389897 -0.273700  ...    -0.017874  -0.284764  -0.008273   \n",
       "1  1.560002 -0.389928 -0.069233  ...    -0.017874  -0.284764  -0.008273   \n",
       "2  1.560002 -0.389964 -0.252044  ...    -0.017874  -0.284764  -0.008273   \n",
       "3  1.560002 -0.389958 -0.275821  ...    -0.017874  -0.284764  -0.008273   \n",
       "4  1.560002 -0.389927 -0.275561  ...    -0.017874  -0.284764  -0.008273   \n",
       "\n",
       "   state_FIN  state_INT  state_PAR  state_REQ  state_RST  state_URN  state_no  \n",
       "0   1.119382  -0.940239  -0.002388   -0.10717  -0.021762  -0.002388 -0.002388  \n",
       "1   1.119382  -0.940239  -0.002388   -0.10717  -0.021762  -0.002388 -0.002388  \n",
       "2   1.119382  -0.940239  -0.002388   -0.10717  -0.021762  -0.002388 -0.002388  \n",
       "3   1.119382  -0.940239  -0.002388   -0.10717  -0.021762  -0.002388 -0.002388  \n",
       "4   1.119382  -0.940239  -0.002388   -0.10717  -0.021762  -0.002388 -0.002388  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# Set up session and bucket\n",
    "session = sagemaker.Session()\n",
    "bucket = 'arjunp-cybersecurity-ml-data1'\n",
    "processed_prefix = 'processed-data'\n",
    "\n",
    "# Download preprocessed data from S3\n",
    "s3 = boto3.client('s3')\n",
    "file_name = 'preprocessed_data.csv'\n",
    "s3.download_file(bucket, f'{processed_prefix}/{file_name}', file_name)\n",
    "\n",
    "# Load into pandas\n",
    "df = pd.read_csv(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b61405e-cca8-40cb-9346-d83a3b87c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('preprocessed_data.csv')\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# CSV for inspection\n",
    "train_df = pd.concat([y_train, X_train], axis=1)\n",
    "test_df = pd.concat([y_test, X_test], axis=1)\n",
    "train_df.to_csv('train.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)\n",
    "\n",
    "# LIBSVM for SageMaker - fixed version\n",
    "dump_svmlight_file(X_train, y_train.values.ravel(), 'train.libsvm')\n",
    "dump_svmlight_file(X_test, y_test.values.ravel(), 'test.libsvm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0ef35d3-fc86-4ded-b460-89927e60300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: s3://arjunp-cybersecurity-ml-data1/xgboost-data/train/train.libsvm\n",
      "Testing data: s3://arjunp-cybersecurity-ml-data1/xgboost-data/test/test.libsvm\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = 'arjunp-cybersecurity-ml-data1'\n",
    "train_prefix = 'xgboost-data/train'\n",
    "test_prefix = 'xgboost-data/test'\n",
    "\n",
    "train_input = session.upload_data('train.libsvm', bucket=bucket, key_prefix=train_prefix)\n",
    "test_input = session.upload_data('test.libsvm', bucket=bucket, key_prefix=test_prefix)\n",
    "\n",
    "print(f\"Training data: {train_input}\")\n",
    "print(f\"Testing data: {test_input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b564bcf7-9405-47fc-8033-fa1b5a61552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "xgboost_image_uri = image_uris.retrieve(\"xgboost\", region=session.boto_region_name, version=\"1.3-1\")\n",
    "\n",
    "xgb = Estimator(\n",
    "    image_uri=xgboost_image_uri,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=f's3://arjunp-cybersecurity-ml-data1/xgboost-model-output',\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(\n",
    "    objective='binary:logistic',\n",
    "    num_round=100,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    verbosity=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afd3950a-9bf1-4096-8b71-5c38c1f21b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2025-11-06-17-56-35-400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-06 17:56:36 Starting - Starting the training job...\n",
      "2025-11-06 17:56:50 Starting - Preparing the instances for training...\n",
      "2025-11-06 17:57:14 Downloading - Downloading input data......\n",
      "2025-11-06 17:58:19 Downloading - Downloading the training image...\n",
      "2025-11-06 17:58:50 Training - Training image download completed. Training in progress..\u001b[34m[2025-11-06 17:58:55.162 ip-10-0-156-37.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2025-11-06 17:58:55.185 ip-10-0-156-37.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:55:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:55:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:55:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:55:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:55:INFO] Determined delimiter of CSV input is ' '\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:55:INFO] Determined delimiter of CSV input is ' '\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:55:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:55:INFO] Determined delimiter of CSV input is ' '\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:57:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:57:INFO] Determined delimiter of CSV input is ' '\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:58:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:58:INFO] Train matrix has 140272 rows and 197 columns\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:58:INFO] Validation matrix has 35069 rows\u001b[0m\n",
      "\u001b[34m[2025-11-06 17:58:58.027 ip-10-0-156-37.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-11-06 17:58:58.028 ip-10-0-156-37.ec2.internal:7 INFO hook.py:207] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-11-06 17:58:58.029 ip-10-0-156-37.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-11-06 17:58:58.029 ip-10-0-156-37.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2025-11-06:17:58:58:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[17:58:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.67003#011validation-logloss:0.66961\u001b[0m\n",
      "\u001b[34m[2025-11-06 17:58:59.038 ip-10-0-156-37.ec2.internal:7 INFO hook.py:428] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2025-11-06 17:58:59.041 ip-10-0-156-37.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.65467#011validation-logloss:0.65432\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.64478#011validation-logloss:0.64431\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.63832#011validation-logloss:0.63795\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.63423#011validation-logloss:0.63372\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.63120#011validation-logloss:0.63097\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.62962#011validation-logloss:0.62921\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.62866#011validation-logloss:0.62799\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.62789#011validation-logloss:0.62723\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.62723#011validation-logloss:0.62665\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.62734#011validation-logloss:0.62640\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.62676#011validation-logloss:0.62617\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.62662#011validation-logloss:0.62608\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.62703#011validation-logloss:0.62587\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.62655#011validation-logloss:0.62593\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.62676#011validation-logloss:0.62579\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.62654#011validation-logloss:0.62579\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.62679#011validation-logloss:0.62568\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.62668#011validation-logloss:0.62580\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.62619#011validation-logloss:0.62577\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.62642#011validation-logloss:0.62579\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.62650#011validation-logloss:0.62574\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.62645#011validation-logloss:0.62570\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.62672#011validation-logloss:0.62572\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.62668#011validation-logloss:0.62572\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.62697#011validation-logloss:0.62562\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.62672#011validation-logloss:0.62565\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.62684#011validation-logloss:0.62581\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.62673#011validation-logloss:0.62572\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.62671#011validation-logloss:0.62563\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.62670#011validation-logloss:0.62559\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.62672#011validation-logloss:0.62566\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.62611#011validation-logloss:0.62578\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.62634#011validation-logloss:0.62576\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.62677#011validation-logloss:0.62572\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.62634#011validation-logloss:0.62577\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.62611#011validation-logloss:0.62578\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.62611#011validation-logloss:0.62578\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.62611#011validation-logloss:0.62578\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.62611#011validation-logloss:0.62579\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.62671#011validation-logloss:0.62563\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.62671#011validation-logloss:0.62564\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.62671#011validation-logloss:0.62565\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.62610#011validation-logloss:0.62572\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.62677#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.62673#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.62678#011validation-logloss:0.62573\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.62673#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.62673#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.62671#011validation-logloss:0.62564\u001b[0m\n",
      "\u001b[34m[50]#011train-logloss:0.62670#011validation-logloss:0.62559\u001b[0m\n",
      "\u001b[34m[51]#011train-logloss:0.62678#011validation-logloss:0.62576\u001b[0m\n",
      "\u001b[34m[52]#011train-logloss:0.62683#011validation-logloss:0.62580\u001b[0m\n",
      "\u001b[34m[53]#011train-logloss:0.62684#011validation-logloss:0.62582\u001b[0m\n",
      "\u001b[34m[54]#011train-logloss:0.62673#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[55]#011train-logloss:0.62678#011validation-logloss:0.62573\u001b[0m\n",
      "\u001b[34m[56]#011train-logloss:0.62683#011validation-logloss:0.62581\u001b[0m\n",
      "\u001b[34m[57]#011train-logloss:0.62672#011validation-logloss:0.62566\u001b[0m\n",
      "\u001b[34m[58]#011train-logloss:0.62679#011validation-logloss:0.62580\u001b[0m\n",
      "\u001b[34m[59]#011train-logloss:0.62679#011validation-logloss:0.62579\u001b[0m\n",
      "\u001b[34m[60]#011train-logloss:0.62679#011validation-logloss:0.62579\u001b[0m\n",
      "\u001b[34m[61]#011train-logloss:0.62673#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[62]#011train-logloss:0.62677#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[63]#011train-logloss:0.62673#011validation-logloss:0.62570\u001b[0m\n",
      "\u001b[34m[64]#011train-logloss:0.62672#011validation-logloss:0.62565\u001b[0m\n",
      "\u001b[34m[65]#011train-logloss:0.62611#011validation-logloss:0.62579\u001b[0m\n",
      "\u001b[34m[66]#011train-logloss:0.62677#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[67]#011train-logloss:0.62673#011validation-logloss:0.62572\u001b[0m\n",
      "\u001b[34m[68]#011train-logloss:0.62677#011validation-logloss:0.62570\u001b[0m\n",
      "\u001b[34m[69]#011train-logloss:0.62673#011validation-logloss:0.62570\u001b[0m\n",
      "\u001b[34m[70]#011train-logloss:0.62677#011validation-logloss:0.62572\u001b[0m\n",
      "\u001b[34m[71]#011train-logloss:0.62677#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[72]#011train-logloss:0.62672#011validation-logloss:0.62565\u001b[0m\n",
      "\u001b[34m[73]#011train-logloss:0.62673#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[74]#011train-logloss:0.62684#011validation-logloss:0.62581\u001b[0m\n",
      "\u001b[34m[75]#011train-logloss:0.62672#011validation-logloss:0.62565\u001b[0m\n",
      "\u001b[34m[76]#011train-logloss:0.62677#011validation-logloss:0.62572\u001b[0m\n",
      "\u001b[34m[77]#011train-logloss:0.62671#011validation-logloss:0.62564\u001b[0m\n",
      "\u001b[34m[78]#011train-logloss:0.62673#011validation-logloss:0.62572\u001b[0m\n",
      "\u001b[34m[79]#011train-logloss:0.62672#011validation-logloss:0.62566\u001b[0m\n",
      "\u001b[34m[80]#011train-logloss:0.62673#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[81]#011train-logloss:0.62684#011validation-logloss:0.62582\u001b[0m\n",
      "\u001b[34m[82]#011train-logloss:0.62678#011validation-logloss:0.62574\u001b[0m\n",
      "\u001b[34m[83]#011train-logloss:0.62679#011validation-logloss:0.62579\u001b[0m\n",
      "\u001b[34m[84]#011train-logloss:0.62677#011validation-logloss:0.62569\u001b[0m\n",
      "\u001b[34m[85]#011train-logloss:0.62677#011validation-logloss:0.62569\u001b[0m\n",
      "\u001b[34m[86]#011train-logloss:0.62672#011validation-logloss:0.62566\u001b[0m\n",
      "\u001b[34m[87]#011train-logloss:0.62677#011validation-logloss:0.62569\u001b[0m\n",
      "\u001b[34m[88]#011train-logloss:0.62677#011validation-logloss:0.62569\u001b[0m\n",
      "\u001b[34m[89]#011train-logloss:0.62678#011validation-logloss:0.62573\u001b[0m\n",
      "\u001b[34m[90]#011train-logloss:0.62684#011validation-logloss:0.62581\u001b[0m\n",
      "\u001b[34m[91]#011train-logloss:0.62677#011validation-logloss:0.62571\u001b[0m\n",
      "\u001b[34m[92]#011train-logloss:0.62634#011validation-logloss:0.62578\u001b[0m\n",
      "\u001b[34m[93]#011train-logloss:0.62633#011validation-logloss:0.62573\u001b[0m\n",
      "\u001b[34m[94]#011train-logloss:0.62671#011validation-logloss:0.62565\u001b[0m\n",
      "\u001b[34m[95]#011train-logloss:0.62671#011validation-logloss:0.62564\u001b[0m\n",
      "\u001b[34m[96]#011train-logloss:0.62673#011validation-logloss:0.62570\u001b[0m\n",
      "\u001b[34m[97]#011train-logloss:0.62673#011validation-logloss:0.62570\u001b[0m\n",
      "\u001b[34m[98]#011train-logloss:0.62673#011validation-logloss:0.62570\u001b[0m\n",
      "\u001b[34m[99]#011train-logloss:0.62672#011validation-logloss:0.62566\u001b[0m\n",
      "\n",
      "2025-11-06 17:59:26 Uploading - Uploading generated training model\n",
      "2025-11-06 17:59:44 Completed - Training job completed\n",
      "Training seconds: 150\n",
      "Billable seconds: 150\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# ✅ Correct S3 paths (match your S3 structure)\n",
    "train_path = 's3://arjunp-cybersecurity-ml-data1/xgboost-data/train/'\n",
    "test_path  = 's3://arjunp-cybersecurity-ml-data1/xgboost-data/test/'\n",
    "\n",
    "# ✅ Create SageMaker TrainingInput objects\n",
    "# content_type must be \"text/csv\" for XGBoost\n",
    "train_input = TrainingInput(s3_data=train_path, content_type='text/csv')\n",
    "test_input  = TrainingInput(s3_data=test_path,  content_type='text/csv')\n",
    "\n",
    "# ✅ Start the training job\n",
    "xgb.fit({'train': train_input, 'validation': test_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "069caa80-300e-4591-bb93-20b092c036cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost==1.7.6\n",
      "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost==1.7.6) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost==1.7.6) (1.15.2)\n",
      "Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m191.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.6\n"
     ]
    }
   ],
   "source": [
    "!pip install --user xgboost==1.7.6 --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4347366a-db26-4d73-b65d-858ca754237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9560865721862614\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.91      0.93     11169\n",
      "         1.0       0.96      0.98      0.97     23900\n",
      "\n",
      "    accuracy                           0.96     35069\n",
      "   macro avg       0.95      0.94      0.95     35069\n",
      "weighted avg       0.96      0.96      0.96     35069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load and convert data\n",
    "train_data = pd.read_csv('train.csv', header=None, dtype=str)\n",
    "test_data = pd.read_csv('test.csv', header=None, dtype=str)\n",
    "\n",
    "# Convert all columns to numeric\n",
    "train_data = train_data.apply(pd.to_numeric, errors='coerce')\n",
    "test_data = test_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop any rows with NaNs\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# Split into features (X) and labels (y)\n",
    "X_train = train_data.iloc[:, 1:]\n",
    "y_train = train_data.iloc[:, 0]\n",
    "X_test = test_data.iloc[:, 1:]\n",
    "y_test = test_data.iloc[:, 0]\n",
    "\n",
    "# Convert to DMatrix format\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# Set parameters and train the model\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"max_depth\": 5,\n",
    "    \"eta\": 0.2,\n",
    "    \"gamma\": 4,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"verbosity\": 1\n",
    "}\n",
    "\n",
    "model = xgb.train(params=params, dtrain=dtrain, num_boost_round=100)\n",
    "\n",
    "# Predict\n",
    "y_pred_prob = model.predict(dtest)\n",
    "y_pred = [1 if p > 0.5 else 0 for p in y_pred_prob]\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7838599-d006-497a-af90-32ab6148b84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model cybersecurity-threat-xgboost registered successfully in SageMaker!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from sagemaker import image_uris\n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "region = \"us-east-1\"\n",
    "bucket_name = \"arjunp-cybersecurity-ml-data1\"\n",
    "model_artifact = f\"s3://arjunp-cybersecurity-ml-data1/xgboost-model-output/sagemaker-xgboost-2025-11-06-17-56-35-400/output/model.tar.gz\"\n",
    "model_name = \"cybersecurity-threat-xgboost\"\n",
    "\n",
    "# Get XGBoost image URI\n",
    "image_uri = image_uris.retrieve(\"xgboost\", region=region, version=\"1.3-1\")\n",
    "\n",
    "# Use actual IAM Role ARN\n",
    "execution_role = \"arn:aws:iam::907759099913:role/SageMakerCybersecurityRole\"\n",
    "\n",
    "# Register the model\n",
    "response = sagemaker_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": image_uri,\n",
    "        \"ModelDataUrl\": model_artifact\n",
    "    },\n",
    "    ExecutionRoleArn=execution_role\n",
    ")\n",
    "\n",
    "print(f\"Model {model_name} registered successfully in SageMaker!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df8fbe4b-12a5-4e6b-9504-7924ef7d6381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint 'cybersecurity-threat-endpoint' is being deployed. This may take a few minutes...\n"
     ]
    }
   ],
   "source": [
    "# Define model name if not already defined\n",
    "model_name = \"cybersecurity-threat-xgboost\"\n",
    "\n",
    "# Define endpoint configuration\n",
    "endpoint_config_name = \"cybersecurity-threat-config\"\n",
    "\n",
    "sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"DefaultVariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.m5.large\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Deploy endpoint\n",
    "endpoint_name = \"cybersecurity-threat-endpoint\"\n",
    "\n",
    "sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(f\"Endpoint '{endpoint_name}' is being deployed. This may take a few minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1aedd46d-6f71-4682-be97-2d73e79e2c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2025-11-06-19-05-11-560\n",
      "INFO:sagemaker:Creating endpoint-config with name cybersecurity-xgboost-endpoint\n",
      "INFO:sagemaker:Creating endpoint with name cybersecurity-xgboost-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!✅ Model deployed successfully at endpoint: cybersecurity-xgboost-endpoint\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker import image_uris\n",
    "\n",
    "region = \"us-east-1\"\n",
    "image_uri = image_uris.retrieve(\"xgboost\", region=region, version=\"1.3-1\")\n",
    "\n",
    "# These should match your earlier ones\n",
    "model_artifact = \"s3://arjunp-cybersecurity-ml-data1/xgboost-model-output/sagemaker-xgboost-2025-11-06-17-56-35-400/output/model.tar.gz\"\n",
    "execution_role = \"arn:aws:iam::907759099913:role/SageMakerCybersecurityRole\"\n",
    "\n",
    "# Create model object\n",
    "xgb_model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_artifact,\n",
    "    role=execution_role\n",
    ")\n",
    "\n",
    "# ✅ Deploy to endpoint\n",
    "endpoint_name = \"cybersecurity-xgboost-endpoint\"\n",
    "\n",
    "predictor = xgb_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    endpoint_name=endpoint_name\n",
    ")\n",
    "\n",
    "print(f\"✅ Model deployed successfully at endpoint: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4bf83a-4c63-4520-8767-5380ddf95576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "\n",
    "runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# Sample input in CSV format\n",
    "sample_input = \"0.5,0.3,0.8,0.2,0.1,0.6,0.9,0.4\"\n",
    "\n",
    "# Invoke the endpoint\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=\"cybersecurity-xgboost-endpoint\",  # or use endpoint_name if defined\n",
    "    ContentType=\"text/csv\",\n",
    "    Body=sample_input\n",
    ")\n",
    "\n",
    "# Get prediction from response\n",
    "result = response[\"Body\"].read().decode(\"utf-8\")\n",
    "prediction_score = float(result.strip())\n",
    "\n",
    "# Interpret prediction\n",
    "predicted_label = \"THREAT\" if prediction_score > 0.5 else \"SAFE\"\n",
    "\n",
    "print(f\"Prediction: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
